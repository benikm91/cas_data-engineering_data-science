ng-template('#slides'='')
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.LINEAR_REGRESSION")
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.DATA_SPECIFICATION")
    section
        slide-with-header(header="Linear Regression - Data Specification")
            // div #[span.highlight Data Specification]: In welcher Form erwartet der Machine Learning Algorithmus die Daten.
            ul
                li.fragment Was ist die kontinuierliche #[span.highlight Ziel-Variable], z.B. #[span.code-font weight (g)]
                li.fragment Welche #[span.highlight Features] wählen wir, z.B. um einen Fisch zu repräsentieren (#[span.code-font width (cm), ...])
                li.fragment
                    data-specification-element-categorical-feature-encoded
                li.fragment
                    span Wenn #[a(href="#/{{conceptLabels.REGULARIZATION.href}}") Regularisiert]:&nbsp;
                    data-specification-element-numerical-feature-standardize
                // li.fragment
                //     div #[span.highlight Anzahl Features] gibt die #[span.highlight Anzahl Parameter] vor.
                //     div Also #[span.highlight mehr Features machen das Modell komplexer].
                // li Features müssen für das Modell #[span.highlight nicht skaliert] werden
                // li Label muss je nach Problemfall #[span.highlight transformiert] werden (Tusky-Anscombe Plot)
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.MODEL")
    section
        slide-with-header(header="Linear Regression - Intuition")
            p Wir möchten das #[span.highlight Gewicht] (weight) anhand eines einzigen Features, der #[span.highlight Breite] (width) vorhersagen.
            .row
                .col-6
                    div.r-stack
                        img(src="assets/images/data.png", data-fragment-index="0").fragment
                        img(src="assets/images/data-with-linear-regression-model.png", data-fragment-index="2").fragment
                .col-6
                    .fragment(data-fragment-index="1") Dazu verwenden wir das folgende #[span.highlight Lineare Modell]
                        div([mathjax]="linearRegression1DExample")
            div.mt-5.d-flex.justify-content-center.fragment
                model-visualization(input-header="Input Space", output-header="Output Space")
                    div(input, class="input").transparent-border-1.code
                        | width: 5cm
                    div(model, class="model").model-box.code
                        div([mathjax]="linearRegression1DExample")
                    div(output, class="output").fix-height.code
                        | weight: 508g
    section
        slide-with-header(header="Linear Regression - Code")
            div.notebook-name Teil 1 in linear_regression.ipynb
            img(src="assets/images/code.png")
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li Unabhängig  vom Problem
                        li Mehrere Features
                        li Bezug zu echten Beobachtungen
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.highlight-step Unabhängig  vom Problem
                        li.unhighlight-step Mehrere Features
                        li.unhighlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegressionGeneralize1DExample")
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.unhighlight-step Unabhängig  vom Problem
                        li.highlight-step  Mehrere Features
                        li.unhighlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegression1DToNDExample")
            div.fragment.text-center.alert.alert-primary Output ist eine #[span.highlight Gewichtete Summe] der Features
    section
        slide-with-header(header="Linear Regression - Theory - Verallgemeinern")
            ul
                li Wir möchten das lineare Modell verallgemeinern
                    ol
                        li.unhighlight-step Unabhängig  vom Problem
                        li.unhighlight-step Mehrere Features
                        li.highlight-step Bezug zu echten Beobachtungen
            div.mt-5.d-flex.justify-start.flex-column
                div([mathjax]="linearRegressionFull")
    section
        slide-with-header(header="\"Ganz simple Mathematik\"")
            div([mathjax]="linearRegressionMathematicalNotation")
            p.fragment.text-center.alert.alert-primary #[span.highlight Nur Notation]: Alle bedeutet das #[span.highlight Gleiche]!

    section
        slide-with-header(header="Linear Regression - Mehrere Features", [extra]="true")
            side-by-side-3
                div(first).d-flex.flex-column
                    h3 1 Feature
                    div([mathjax]="linearRegression1D", style={fontSize: "14pt"})
                    img(src="assets/images/data-with-linear-regression-model-1d.png").fragment
                div(second).d-flex.flex-column
                    h3 2 Feature
                    div([mathjax]="linearRegression2D", style={fontSize: "14pt"})
                    div.r-stack
                        img(src="assets/images/data-2d.png").fragment
                        img(src="assets/images/data-with-linear-regression-model-2d.png").fragment
                div(third).d-flex.flex-column
                    h3 3 Feature
                    div([mathjax]="linearRegression3D", style={fontSize: "14pt"})
                    div.fragment
                        div(style={marginTop: "100px"}).w-100
                            div.m-auto ???
            p.fragment.text-center.alert.alert-primary #[span.highlight Visualisierung] gut für #[span.highlight Intuition].#[br]#[span.highlight Mathematik] verallgemeinert auf #[span.highlight höhere Dimensionen].
    question-slide([questions]="linearRegressionQuestions")
    tables-of-content-concepts([active]="conceptLabels.REGRESSION_METRICS")
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Fehler eines Modells messen?")
            ul
                li.fragment
                    div #[span.highlight Residuals] messen Fehler pro Datenpunkt
                    div.d-flex.justify-center
                        img(style={width: "350px"}, src="assets/images/linear-regression-model-residuals.png").img-fluid
                    div([mathjax]='metricResiduals')
                li.fragment Residuals zu einer Zahl zusammenfassen => #[span.highlight Metrik]
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Metrik")
            ul
                li Wie gewichten wir die Fehler pro Datenpunkt?
                    ul.fragment
                        li Sind alle Fehler gleich zu bewerten?
                        li Sind gröbere Fehler mehr zu bestrafen?
                        li Sind Fehler Absolut oder Prozentual zu bestrafen?
                li.fragment Die Wahl der #[span.highlight Metrik] gibt vor wie Fehler zu gewichten sind.
            p.mt-5.fragment.text-center.alert.alert-primary Welche Metrik geeignet ist, ist #[span.highlight Problemabhängig]!
    section
        slide-with-header(header="{{problemLabels.REGRESSION.label}} - Metrik - Beispiele")
            ul
                li.fragment #[span.highlight MAE]: #[span.highlight M]ean #[span.highlight A]bsolute #[span.highlight E]rror
                    div.r-stack
                        div.fragment([mathjax]="metricMeanAbsoluteError")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorE")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorA")
                        div.fragment([mathjax]="metricMeanAbsoluteErrorM")
                        div.fragment([mathjax]="metricMeanAbsoluteError")
                li.fragment
                    div #[span.highlight MSE]: #[span.highlight M]ean #[span.highlight S]quared #[span.highlight E]rror
                    div.r-stack
                        div.fragment([mathjax]="metricMeanSquaredError")
                        div.fragment([mathjax]="metricMeanSquaredErrorE")
                        div.fragment([mathjax]="metricMeanSquaredErrorS")
                        div.fragment([mathjax]="metricMeanSquaredErrorM")
                        div.fragment([mathjax]="metricMeanSquaredError")
            p.fragment.text-center.alert.alert-primary MSE bestraft im Vergleich zu MAE Fehler grösser 1 stärker und Fehler kleiner 1 schwächer.
    tables-of-content-concepts([active]="conceptLabels.COST_FUNCTION")
    section
        slide-with-header([header]="'Kostenfunktion'")
            div(style={marginBottom: "-10px"}).fragment
                div([mathjax]="metricCostFunctionMSE")
            div.mt-5.fragment Beispiel (Lineare Regression mit 2 Parameter):
                div([mathjax]="metricCostFunctionMSE1D")
            p.fragment.text-center.alert.alert-warning Synonym: #[span.highlight Kostenfunktion] = Loss f. = Objective f.
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.COST_FUNCTION")
    section
        slide-with-header(header="Linear Regression - Kostenfunktion")
            div([mathjax]="metricCostFunctionMSECompact")
            div.fragment.mt-5.text-center.alert.alert-primary
                div Im #[span.code-font sklearn] wird #[span.code-font LinearRegression] nach der MSE-Kostenfunktion optimiert.
                div Es wären andere Kostenfunktionen möglich.
    // section
    //     slide-with-header(header="Linear Regression - Kostenfunktion - Motivation", [extra]="true")
    //         div.small-font
    //             .row
    //                 .col-6
    //                     h5 Annahmen
    //                     ul
    //                         li #[span.highlight Lineares Modell]: Linearer Zusammenhang von Ziel und Features plus ein unabhängiger Fehler
    //                         li Der unabhängige Fehler ist normalverteilt: #[span([mathjax]="noiseNormalDistributed")]
    //                 .col-6
    //                     h5 Konsequenzen
    //                     div Diese Annahmen führt #[span.highlight mathematisch zur MSE Metrik].
    //         div.mt-3
    //             img(src="assets/images/regression/linear-regression-cost-function-motivation.png", height="290px")
    //         div.mt-3.fragment.text-center.alert.alert-primary "Der Fehler ist normalverteilt" ist motiviert durch das #[a.highlight(href="https://en.wikipedia.org/wiki/Central_limit_theorem") Central Limit Theorem]
    section
        slide-with-header(header="Linear Regression - Code")
            div.notebook-name Teil 2 in in linear_regression.ipynb
            img(src="assets/images/code.png")
    tables-of-content-concepts([active]="conceptLabels.OPTIMIZATION_ALGORITHMS")
    section
        slide-with-header(header="Optimierung")
            ul
                li
                    | Optimierung ist der Mechanismus, wie wir die #[span.highlight lernbaren Parameter] eines Models
                    | für eine #[span.highlight Kostenfunktion] aus #[span.highlight Daten] lernen.
                li.fragment Unterschiedliche Optimierungs-Algorithmen existieren
                li.fragment Unterschiedliche Garantien
                    ul
                        li #[span.highlight Performanz]: Wie schnell
                        li (#[span.highlight Generalisierung]: Qualität)
    tables-of-content-machine-learning-algorithm([active]="linearRegressionLabels.OPTIMIERUNG")
        .fragment.alert.alert-primary.smaller-font Analytisch oder Gradient Descent (schauen wir hier nicht an)
    section
        slide-with-header(header="Linear Regression - Limits", [extra]="true")
            div.row
                div.col-5.offset-1
                    h6 Possible
                div.col-5
                    h6 Impossible (in Feature Space)
                div.col-1
            div.row.fragment
                div.col-1.m-auto
                    h6(style={transform: "rotate(-90deg)", whiteSpace: 'nowrap'}) 1 Feature
                div.col-5.p-2
                    img(src="assets/images/data-with-linear-regression-model-1d.png").limit-possible
                div.col-5.p-2
                    img(src="assets/images/polynomial-regression.png").limit-impossible
                div.col-1
            div.row.fragment
                div.col-1.m-auto
                    h6(style={transform: "rotate(-90deg)", whiteSpace: 'nowrap'}) 2 Features
                div.col-5.p-2
                    img(src="assets/images/data-with-linear-regression-model-2d.png").limit-possible
                div.col-5.p-2
                    img(src="assets/images/polynomial-regression-2d.png").limit-impossible
                div.col-1
